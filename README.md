Hereâ€™s your cleaned version of the README.md for Voice_Extractor, no weird text â€” fully polished, ready to paste:

â¸»

Voice_Extractor

A powerful AI pipeline for identifying, isolating, and transcribing clean solo segments of a target speaker from multi-speaker audio recordings.

â¸»

Team Name: FitnessGram

Members:
	â€¢	Lwazi Mabota
	â€¢	Resis Cook
	â€¢	Zafar Ahmad
	â€¢	Jian Zhou

â¸»

Introduction

Use Case: Automatically extract speech segments from a target speaker in noisy, multi-speaker audio.

Purpose: Enable creation of clean speaker datasets, improve podcast/audio editing, and enhance research in speaker-based AI.

Target Users:
	â€¢	Podcast editors and producers
	â€¢	Speech data scientists
	â€¢	Voice biometric researchers
	â€¢	Transcription professionals

â¸»

Problem Statement & Objective

Manual extraction of speaker-specific segments is tedious and error-prone. Our objective is to automate:
	â€¢	Diarization: Identify who speaks when
	â€¢	Overlap detection: Remove multi-speaker overlap
	â€¢	Target matching: Select segments matching a reference speaker
	â€¢	Verification: Confirm speaker match with multi-stage verification
	â€¢	Transcription: Generate high-quality transcripts of verified segments
	â€¢	Visualization: Provide plots for verification confidence

â¸»

Model Selection & Justification

Diarization
	â€¢	PyAnnote speaker-diarization-3.1
State-of-the-art diarization accuracy.

Overlap Detection
	â€¢	PyAnnote overlapped-speech-detection
Enables removal of overlapping speech segments.

Speaker Matching
	â€¢	WeSpeaker Deep r-vector (English)
Robust target speaker embedding and matching.

Speaker Verification
	â€¢	WeSpeaker Gemini model + SpeechBrain ECAPA-TDNN
Multi-stage verification for maximum accuracy.

Vocal Separation (optional)
	â€¢	Bandit-v2
Cinematic audio separation to isolate vocals from music/effects.

Transcription
	â€¢	OpenAI Whisper (large-v3)
Best-in-class transcription accuracy.

â¸»

System Architecture

Pipeline Flow
	â€¢	Audio â†’ PyAnnote diarization + overlap detection â†’ clean speaker segments
	â€¢	Segments â†’ WeSpeaker target matching â†’ candidate segments
	â€¢	Candidates â†’ Multi-stage verification â†’ final verified segments
	â€¢	(Optional) Bandit-v2 â†’ improved isolated vocals
	â€¢	Final segments â†’ Whisper â†’ transcription
	â€¢	Outputs â†’ WAV + CSV/TXT transcripts + visualizations

â¸»

Live Demo

Google Colab Version

ðŸ‘‰ Run on Colab

Run Locally

pip install -r requirements.txt

python run_extractor.py \
--input-audio "path/to/input_audio.wav" \
--reference-audio "path/to/target_sample.wav" \
--target-name "TargetName" \
--token "hf_YourHuggingFaceToken"


â¸»

Required Model Access

Request access to the following gated repos:
	â€¢	https://huggingface.co/pyannote/speaker-diarization-3.1
	â€¢	https://huggingface.co/pyannote/overlapped-speech-detection
	â€¢	https://huggingface.co/pyannote/segmentation-3.0
	â€¢	https://huggingface.co/pyannote/segmentation

â¸»

Evaluation & User Feedback

Metrics
	â€¢	Speaker verification accuracy: > 95% on clean samples, ~88% on noisy real-world audio
	â€¢	BLEU / WER scores (Whisper transcriptions) validated on internal podcast & meeting datasets

User Survey
	â€¢	Segmentation quality: 4.5/5
	â€¢	Verification correctness: 4.7/5
	â€¢	Transcription accuracy: 4.6/5
	â€¢	Visualization clarity: 4.8/5

Example Scenario

Input: Multi-speaker podcast (3 speakers)
Target: Host A (reference sample provided)
Output:
	â€¢	Verified segments of Host A only (non-overlapped)
	â€¢	Clean WAV files
	â€¢	CSV + TXT transcriptions
	â€¢	Verification score plots & spectrograms

â¸»

Strengths
	â€¢	High-quality speaker isolation
	â€¢	Accurate multi-stage verification
	â€¢	Flexible and modular pipeline
	â€¢	Excellent visualization tools

â¸»

Limitations
	â€¢	Requires 16GB+ VRAM GPU
	â€¢	OSD imperfect on very noisy speech
	â€¢	Manual tuning of verification threshold required

â¸»

Conclusion & Future Work

What Worked
	â€¢	Highly accurate pipeline
	â€¢	Modular CLI with flexible options
	â€¢	Robust real-world performance

Improvements Needed
	â€¢	Faster processing for long audio
	â€¢	Improved OSD on noisy files
	â€¢	More user-friendly GUI

Next Steps
	â€¢	Real-time / streaming extraction
	â€¢	Speaker diarization web explorer
	â€¢	Multi-target speaker extraction
	â€¢	Domain adaptation for TV, call centers, podcasting

â¸»

Tech Stack
	â€¢	AI Models:
	â€¢	Bandit-v2 (source separation)
	â€¢	PyAnnote (diarization & overlap detection)
	â€¢	WeSpeaker r-vector + Gemini verification
	â€¢	SpeechBrain ECAPA-TDNN
	â€¢	OpenAI Whisper large-v3
	â€¢	Silero VAD
	â€¢	Libraries:
	â€¢	PyTorch
	â€¢	torchaudio
	â€¢	torchvision
	â€¢	librosa
	â€¢	asteroid
	â€¢	ffmpeg-python
	â€¢	ray

â¸»

License

MIT License
